{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "\n",
    "import torch\n",
    "\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "\n",
    "from tqdm import tqdm\n",
    "import ast"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "folder = '/dlabdata1/lugeon/'\n",
    "name = 'websites_40000_5cat_emb.gz'\n",
    "data = pd.read_csv(folder + name, \n",
    "                   header=0,\n",
    "                   index_col = 0,\n",
    "                   names=['emb', 'cat0'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = data[data.emb.notnull()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "data['emb'] = data.apply(lambda row: np.array(ast.literal_eval(row.emb)), axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>emb</th>\n",
       "      <th>cat0</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>[-0.0009275737561677632, -0.02362455401504249,...</td>\n",
       "      <td>Arts</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>[0.04585096571180555, -0.018588595920138888, 0...</td>\n",
       "      <td>Arts</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>[-0.009650490500710228, -0.02681940252130682, ...</td>\n",
       "      <td>Arts</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>[0.04253146113181601, 0.036278354878328284, 0....</td>\n",
       "      <td>Arts</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>[-0.07145182291666667, 0.0058917999267578125, ...</td>\n",
       "      <td>Arts</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                 emb  cat0\n",
       "0  [-0.0009275737561677632, -0.02362455401504249,...  Arts\n",
       "1  [0.04585096571180555, -0.018588595920138888, 0...  Arts\n",
       "2  [-0.009650490500710228, -0.02681940252130682, ...  Arts\n",
       "4  [0.04253146113181601, 0.036278354878328284, 0....  Arts\n",
       "5  [-0.07145182291666667, 0.0058917999267578125, ...  Arts"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(150192, 2)"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Science      31772\n",
       "Computers    31235\n",
       "Kids         30741\n",
       "Arts         29484\n",
       "Sports       26960\n",
       "Name: cat0, dtype: int64"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.cat0.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "def categorize(s):\n",
    "    if s == 'Kids':\n",
    "        return 0\n",
    "    if s == 'Science':\n",
    "        return 1\n",
    "    if s == 'Arts':\n",
    "        return 2\n",
    "    if s == 'Computers':\n",
    "        return 3\n",
    "    if s == 'Sports':\n",
    "        return 4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "data['cat_no'] = data.apply(lambda row: categorize(row.cat0), axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "embeddings = np.concatenate(data.emb.values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "embedding_dim = 300\n",
    "train_input = torch.tensor(embeddings)\n",
    "train_input = torch.reshape(train_input, (-1, embedding_dim)).float()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([150192, 300])"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_input.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "cat_no = data.cat_no.values\n",
    "train_target = torch.tensor(cat_no).long()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([150192])"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_target.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "id = np.arange(train_input.shape[0])\n",
    "np.random.shuffle(id)\n",
    "\n",
    "tr_id = id[:140_000]\n",
    "te_id = id[140_000:]\n",
    "\n",
    "train_input_ = train_input[tr_id]\n",
    "test_input_ = train_input[te_id]\n",
    "\n",
    "train_target_ = train_target[tr_id]\n",
    "test_target_ = train_target[te_id]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Science      29651\n",
       "Computers    29084\n",
       "Kids         28660\n",
       "Arts         27486\n",
       "Sports       25119\n",
       "Name: cat0, dtype: int64"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.iloc[tr_id].cat0.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch import nn\n",
    "from torch.nn import functional as F\n",
    "from torch import optim\n",
    "import time\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Classifier(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(Classifier, self).__init__()\n",
    "        self.fc1 = nn.Linear(300, 100)\n",
    "        self.fc2 = nn.Linear(100, 20)\n",
    "        self.fc3 = nn.Linear(20, 5)\n",
    "        self.drop = nn.Dropout(0.1)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.fc1(x)\n",
    "        x = self.drop(x)\n",
    "        x = self.fc2(F.relu(x))\n",
    "        x = self.drop(x)\n",
    "        x = self.fc3(F.relu(x))\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "def accuracy(output, target):\n",
    "    nb_samples = output.shape[0]\n",
    "    \n",
    "    # Convert probability to decision\n",
    "    output_class = torch.argmax(output, 1)\n",
    "    \n",
    "    nb_correct = (output_class == target).sum().item()\n",
    "    return nb_correct / nb_samples\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0 | Train loss : 1.007 | Train accuracy : 0.612 | Test accuracy : 0.612\n",
      "Epoch 1 | Train loss : 0.957 | Train accuracy : 0.628 | Test accuracy : 0.627\n",
      "Epoch 2 | Train loss : 0.932 | Train accuracy : 0.636 | Test accuracy : 0.631\n",
      "Epoch 3 | Train loss : 0.916 | Train accuracy : 0.640 | Test accuracy : 0.636\n",
      "Epoch 4 | Train loss : 0.901 | Train accuracy : 0.643 | Test accuracy : 0.637\n",
      "Epoch 5 | Train loss : 0.897 | Train accuracy : 0.644 | Test accuracy : 0.638\n",
      "Epoch 6 | Train loss : 0.891 | Train accuracy : 0.646 | Test accuracy : 0.642\n",
      "Epoch 7 | Train loss : 0.884 | Train accuracy : 0.649 | Test accuracy : 0.642\n",
      "Epoch 8 | Train loss : 0.884 | Train accuracy : 0.648 | Test accuracy : 0.643\n",
      "Epoch 9 | Train loss : 0.868 | Train accuracy : 0.651 | Test accuracy : 0.644\n",
      "Epoch 10 | Train loss : 0.873 | Train accuracy : 0.650 | Test accuracy : 0.643\n",
      "Epoch 11 | Train loss : 0.867 | Train accuracy : 0.653 | Test accuracy : 0.645\n",
      "Epoch 12 | Train loss : 0.859 | Train accuracy : 0.656 | Test accuracy : 0.648\n",
      "Epoch 13 | Train loss : 0.859 | Train accuracy : 0.655 | Test accuracy : 0.647\n",
      "Epoch 14 | Train loss : 0.855 | Train accuracy : 0.656 | Test accuracy : 0.646\n",
      "Epoch 15 | Train loss : 0.855 | Train accuracy : 0.656 | Test accuracy : 0.648\n",
      "Epoch 16 | Train loss : 0.857 | Train accuracy : 0.655 | Test accuracy : 0.648\n",
      "Epoch 17 | Train loss : 0.850 | Train accuracy : 0.658 | Test accuracy : 0.651\n",
      "Epoch 18 | Train loss : 0.850 | Train accuracy : 0.657 | Test accuracy : 0.650\n",
      "Epoch 19 | Train loss : 0.844 | Train accuracy : 0.658 | Test accuracy : 0.651\n",
      "Epoch 20 | Train loss : 0.844 | Train accuracy : 0.659 | Test accuracy : 0.651\n",
      "Epoch 21 | Train loss : 0.843 | Train accuracy : 0.662 | Test accuracy : 0.657\n",
      "Epoch 22 | Train loss : 0.839 | Train accuracy : 0.663 | Test accuracy : 0.653\n",
      "Epoch 23 | Train loss : 0.841 | Train accuracy : 0.662 | Test accuracy : 0.653\n",
      "Epoch 24 | Train loss : 0.839 | Train accuracy : 0.662 | Test accuracy : 0.653\n",
      "Epoch 25 | Train loss : 0.832 | Train accuracy : 0.665 | Test accuracy : 0.656\n",
      "Epoch 26 | Train loss : 0.832 | Train accuracy : 0.664 | Test accuracy : 0.656\n",
      "Epoch 27 | Train loss : 0.832 | Train accuracy : 0.665 | Test accuracy : 0.656\n",
      "Epoch 28 | Train loss : 0.829 | Train accuracy : 0.665 | Test accuracy : 0.656\n",
      "Epoch 29 | Train loss : 0.831 | Train accuracy : 0.664 | Test accuracy : 0.655\n",
      "Epoch 30 | Train loss : 0.829 | Train accuracy : 0.665 | Test accuracy : 0.656\n",
      "Epoch 31 | Train loss : 0.827 | Train accuracy : 0.666 | Test accuracy : 0.653\n",
      "Epoch 32 | Train loss : 0.824 | Train accuracy : 0.667 | Test accuracy : 0.656\n",
      "Epoch 33 | Train loss : 0.825 | Train accuracy : 0.666 | Test accuracy : 0.654\n",
      "Epoch 34 | Train loss : 0.824 | Train accuracy : 0.666 | Test accuracy : 0.655\n",
      "Epoch 35 | Train loss : 0.821 | Train accuracy : 0.666 | Test accuracy : 0.653\n",
      "Epoch 36 | Train loss : 0.821 | Train accuracy : 0.668 | Test accuracy : 0.655\n",
      "Epoch 37 | Train loss : 0.818 | Train accuracy : 0.671 | Test accuracy : 0.658\n",
      "Epoch 38 | Train loss : 0.821 | Train accuracy : 0.667 | Test accuracy : 0.652\n",
      "Epoch 39 | Train loss : 0.820 | Train accuracy : 0.668 | Test accuracy : 0.656\n",
      "Epoch 40 | Train loss : 0.816 | Train accuracy : 0.669 | Test accuracy : 0.656\n",
      "Epoch 41 | Train loss : 0.817 | Train accuracy : 0.669 | Test accuracy : 0.656\n",
      "Epoch 42 | Train loss : 0.820 | Train accuracy : 0.670 | Test accuracy : 0.658\n",
      "Epoch 43 | Train loss : 0.813 | Train accuracy : 0.673 | Test accuracy : 0.658\n",
      "Epoch 44 | Train loss : 0.814 | Train accuracy : 0.671 | Test accuracy : 0.658\n",
      "Epoch 45 | Train loss : 0.817 | Train accuracy : 0.669 | Test accuracy : 0.657\n",
      "Epoch 46 | Train loss : 0.813 | Train accuracy : 0.670 | Test accuracy : 0.652\n",
      "Epoch 47 | Train loss : 0.812 | Train accuracy : 0.671 | Test accuracy : 0.656\n",
      "Epoch 48 | Train loss : 0.814 | Train accuracy : 0.670 | Test accuracy : 0.653\n",
      "Epoch 49 | Train loss : 0.812 | Train accuracy : 0.672 | Test accuracy : 0.656\n",
      "Epoch 50 | Train loss : 0.810 | Train accuracy : 0.675 | Test accuracy : 0.661\n",
      "Epoch 51 | Train loss : 0.809 | Train accuracy : 0.673 | Test accuracy : 0.657\n",
      "Epoch 52 | Train loss : 0.809 | Train accuracy : 0.675 | Test accuracy : 0.661\n",
      "Epoch 53 | Train loss : 0.809 | Train accuracy : 0.674 | Test accuracy : 0.658\n",
      "Epoch 54 | Train loss : 0.808 | Train accuracy : 0.672 | Test accuracy : 0.657\n",
      "Epoch 55 | Train loss : 0.810 | Train accuracy : 0.673 | Test accuracy : 0.662\n",
      "Epoch 56 | Train loss : 0.809 | Train accuracy : 0.672 | Test accuracy : 0.654\n",
      "Epoch 57 | Train loss : 0.808 | Train accuracy : 0.672 | Test accuracy : 0.655\n",
      "Epoch 58 | Train loss : 0.810 | Train accuracy : 0.673 | Test accuracy : 0.658\n",
      "Epoch 59 | Train loss : 0.806 | Train accuracy : 0.672 | Test accuracy : 0.659\n",
      "Epoch 60 | Train loss : 0.803 | Train accuracy : 0.672 | Test accuracy : 0.658\n",
      "Epoch 61 | Train loss : 0.805 | Train accuracy : 0.673 | Test accuracy : 0.656\n",
      "Epoch 62 | Train loss : 0.805 | Train accuracy : 0.674 | Test accuracy : 0.659\n",
      "Epoch 63 | Train loss : 0.803 | Train accuracy : 0.674 | Test accuracy : 0.658\n",
      "Epoch 64 | Train loss : 0.806 | Train accuracy : 0.674 | Test accuracy : 0.657\n",
      "Epoch 65 | Train loss : 0.802 | Train accuracy : 0.674 | Test accuracy : 0.661\n",
      "Epoch 66 | Train loss : 0.803 | Train accuracy : 0.675 | Test accuracy : 0.658\n",
      "Epoch 67 | Train loss : 0.804 | Train accuracy : 0.673 | Test accuracy : 0.658\n",
      "Epoch 68 | Train loss : 0.800 | Train accuracy : 0.676 | Test accuracy : 0.659\n",
      "Epoch 69 | Train loss : 0.805 | Train accuracy : 0.675 | Test accuracy : 0.661\n",
      "Epoch 70 | Train loss : 0.798 | Train accuracy : 0.676 | Test accuracy : 0.660\n",
      "Epoch 71 | Train loss : 0.802 | Train accuracy : 0.676 | Test accuracy : 0.663\n",
      "Epoch 72 | Train loss : 0.803 | Train accuracy : 0.675 | Test accuracy : 0.659\n",
      "Epoch 73 | Train loss : 0.801 | Train accuracy : 0.673 | Test accuracy : 0.658\n",
      "Epoch 74 | Train loss : 0.803 | Train accuracy : 0.674 | Test accuracy : 0.660\n",
      "Epoch 75 | Train loss : 0.798 | Train accuracy : 0.676 | Test accuracy : 0.662\n",
      "Epoch 76 | Train loss : 0.799 | Train accuracy : 0.675 | Test accuracy : 0.660\n",
      "Epoch 77 | Train loss : 0.796 | Train accuracy : 0.677 | Test accuracy : 0.663\n",
      "Epoch 78 | Train loss : 0.797 | Train accuracy : 0.676 | Test accuracy : 0.658\n",
      "Epoch 79 | Train loss : 0.800 | Train accuracy : 0.676 | Test accuracy : 0.662\n",
      "Epoch 80 | Train loss : 0.800 | Train accuracy : 0.674 | Test accuracy : 0.658\n",
      "Epoch 81 | Train loss : 0.795 | Train accuracy : 0.678 | Test accuracy : 0.664\n",
      "Epoch 82 | Train loss : 0.795 | Train accuracy : 0.676 | Test accuracy : 0.662\n",
      "Epoch 83 | Train loss : 0.794 | Train accuracy : 0.678 | Test accuracy : 0.663\n",
      "Epoch 84 | Train loss : 0.795 | Train accuracy : 0.676 | Test accuracy : 0.663\n",
      "Epoch 85 | Train loss : 0.797 | Train accuracy : 0.675 | Test accuracy : 0.661\n",
      "Epoch 86 | Train loss : 0.791 | Train accuracy : 0.679 | Test accuracy : 0.661\n",
      "Epoch 87 | Train loss : 0.796 | Train accuracy : 0.678 | Test accuracy : 0.664\n",
      "Epoch 88 | Train loss : 0.797 | Train accuracy : 0.677 | Test accuracy : 0.659\n",
      "Epoch 89 | Train loss : 0.794 | Train accuracy : 0.679 | Test accuracy : 0.664\n",
      "Epoch 90 | Train loss : 0.794 | Train accuracy : 0.679 | Test accuracy : 0.663\n",
      "Epoch 91 | Train loss : 0.790 | Train accuracy : 0.679 | Test accuracy : 0.663\n",
      "Epoch 92 | Train loss : 0.791 | Train accuracy : 0.680 | Test accuracy : 0.666\n",
      "Epoch 93 | Train loss : 0.791 | Train accuracy : 0.681 | Test accuracy : 0.663\n",
      "Epoch 94 | Train loss : 0.790 | Train accuracy : 0.680 | Test accuracy : 0.663\n",
      "Epoch 95 | Train loss : 0.796 | Train accuracy : 0.680 | Test accuracy : 0.663\n",
      "Epoch 96 | Train loss : 0.792 | Train accuracy : 0.677 | Test accuracy : 0.658\n",
      "Epoch 97 | Train loss : 0.790 | Train accuracy : 0.678 | Test accuracy : 0.662\n",
      "Epoch 98 | Train loss : 0.792 | Train accuracy : 0.677 | Test accuracy : 0.662\n",
      "Epoch 99 | Train loss : 0.791 | Train accuracy : 0.677 | Test accuracy : 0.664\n",
      "Epoch 100 | Train loss : 0.793 | Train accuracy : 0.678 | Test accuracy : 0.661\n",
      "Epoch 101 | Train loss : 0.788 | Train accuracy : 0.679 | Test accuracy : 0.665\n",
      "Epoch 102 | Train loss : 0.792 | Train accuracy : 0.677 | Test accuracy : 0.661\n",
      "Epoch 103 | Train loss : 0.789 | Train accuracy : 0.678 | Test accuracy : 0.659\n",
      "Epoch 104 | Train loss : 0.787 | Train accuracy : 0.680 | Test accuracy : 0.664\n",
      "Epoch 105 | Train loss : 0.793 | Train accuracy : 0.678 | Test accuracy : 0.663\n",
      "Epoch 106 | Train loss : 0.787 | Train accuracy : 0.680 | Test accuracy : 0.660\n",
      "Epoch 107 | Train loss : 0.787 | Train accuracy : 0.681 | Test accuracy : 0.665\n",
      "Epoch 108 | Train loss : 0.786 | Train accuracy : 0.677 | Test accuracy : 0.659\n",
      "Epoch 109 | Train loss : 0.787 | Train accuracy : 0.681 | Test accuracy : 0.666\n",
      "Epoch 110 | Train loss : 0.785 | Train accuracy : 0.680 | Test accuracy : 0.662\n",
      "Epoch 111 | Train loss : 0.788 | Train accuracy : 0.678 | Test accuracy : 0.662\n",
      "Epoch 112 | Train loss : 0.788 | Train accuracy : 0.680 | Test accuracy : 0.662\n",
      "Epoch 113 | Train loss : 0.793 | Train accuracy : 0.679 | Test accuracy : 0.662\n",
      "Epoch 114 | Train loss : 0.788 | Train accuracy : 0.681 | Test accuracy : 0.664\n",
      "Epoch 115 | Train loss : 0.786 | Train accuracy : 0.682 | Test accuracy : 0.664\n",
      "Epoch 116 | Train loss : 0.785 | Train accuracy : 0.682 | Test accuracy : 0.665\n",
      "Epoch 117 | Train loss : 0.789 | Train accuracy : 0.678 | Test accuracy : 0.661\n",
      "Epoch 118 | Train loss : 0.784 | Train accuracy : 0.682 | Test accuracy : 0.666\n",
      "Epoch 119 | Train loss : 0.783 | Train accuracy : 0.683 | Test accuracy : 0.666\n",
      "Epoch 120 | Train loss : 0.782 | Train accuracy : 0.680 | Test accuracy : 0.660\n",
      "Epoch 121 | Train loss : 0.783 | Train accuracy : 0.679 | Test accuracy : 0.662\n",
      "Epoch 122 | Train loss : 0.782 | Train accuracy : 0.683 | Test accuracy : 0.664\n",
      "Epoch 123 | Train loss : 0.785 | Train accuracy : 0.682 | Test accuracy : 0.665\n",
      "Epoch 124 | Train loss : 0.781 | Train accuracy : 0.683 | Test accuracy : 0.667\n",
      "Epoch 125 | Train loss : 0.786 | Train accuracy : 0.681 | Test accuracy : 0.660\n",
      "Epoch 126 | Train loss : 0.783 | Train accuracy : 0.683 | Test accuracy : 0.664\n",
      "Epoch 127 | Train loss : 0.781 | Train accuracy : 0.683 | Test accuracy : 0.663\n",
      "Epoch 128 | Train loss : 0.781 | Train accuracy : 0.683 | Test accuracy : 0.662\n",
      "Epoch 129 | Train loss : 0.783 | Train accuracy : 0.680 | Test accuracy : 0.659\n",
      "Epoch 130 | Train loss : 0.780 | Train accuracy : 0.682 | Test accuracy : 0.663\n",
      "Epoch 131 | Train loss : 0.782 | Train accuracy : 0.684 | Test accuracy : 0.667\n",
      "Epoch 132 | Train loss : 0.784 | Train accuracy : 0.683 | Test accuracy : 0.664\n",
      "Epoch 133 | Train loss : 0.785 | Train accuracy : 0.681 | Test accuracy : 0.664\n",
      "Epoch 134 | Train loss : 0.781 | Train accuracy : 0.684 | Test accuracy : 0.666\n",
      "Epoch 135 | Train loss : 0.783 | Train accuracy : 0.681 | Test accuracy : 0.661\n",
      "Epoch 136 | Train loss : 0.778 | Train accuracy : 0.685 | Test accuracy : 0.666\n",
      "Epoch 137 | Train loss : 0.780 | Train accuracy : 0.683 | Test accuracy : 0.665\n",
      "Epoch 138 | Train loss : 0.786 | Train accuracy : 0.681 | Test accuracy : 0.663\n",
      "Epoch 139 | Train loss : 0.780 | Train accuracy : 0.682 | Test accuracy : 0.660\n",
      "Epoch 140 | Train loss : 0.781 | Train accuracy : 0.683 | Test accuracy : 0.665\n",
      "Epoch 141 | Train loss : 0.781 | Train accuracy : 0.683 | Test accuracy : 0.662\n",
      "Epoch 142 | Train loss : 0.778 | Train accuracy : 0.683 | Test accuracy : 0.663\n",
      "Epoch 143 | Train loss : 0.781 | Train accuracy : 0.682 | Test accuracy : 0.663\n",
      "Epoch 144 | Train loss : 0.777 | Train accuracy : 0.684 | Test accuracy : 0.664\n",
      "Epoch 145 | Train loss : 0.781 | Train accuracy : 0.684 | Test accuracy : 0.662\n",
      "Epoch 146 | Train loss : 0.779 | Train accuracy : 0.684 | Test accuracy : 0.665\n",
      "Epoch 147 | Train loss : 0.780 | Train accuracy : 0.684 | Test accuracy : 0.666\n",
      "Epoch 148 | Train loss : 0.779 | Train accuracy : 0.683 | Test accuracy : 0.665\n",
      "Epoch 149 | Train loss : 0.779 | Train accuracy : 0.684 | Test accuracy : 0.667\n",
      "Epoch 150 | Train loss : 0.773 | Train accuracy : 0.684 | Test accuracy : 0.665\n",
      "Epoch 151 | Train loss : 0.778 | Train accuracy : 0.685 | Test accuracy : 0.666\n",
      "Epoch 152 | Train loss : 0.775 | Train accuracy : 0.684 | Test accuracy : 0.663\n",
      "Epoch 153 | Train loss : 0.778 | Train accuracy : 0.685 | Test accuracy : 0.667\n",
      "Epoch 154 | Train loss : 0.777 | Train accuracy : 0.686 | Test accuracy : 0.667\n",
      "Epoch 155 | Train loss : 0.779 | Train accuracy : 0.683 | Test accuracy : 0.660\n",
      "Epoch 156 | Train loss : 0.774 | Train accuracy : 0.685 | Test accuracy : 0.665\n",
      "Epoch 157 | Train loss : 0.780 | Train accuracy : 0.682 | Test accuracy : 0.660\n",
      "Epoch 158 | Train loss : 0.776 | Train accuracy : 0.686 | Test accuracy : 0.668\n",
      "Epoch 159 | Train loss : 0.778 | Train accuracy : 0.685 | Test accuracy : 0.663\n",
      "Epoch 160 | Train loss : 0.778 | Train accuracy : 0.685 | Test accuracy : 0.664\n",
      "Epoch 161 | Train loss : 0.774 | Train accuracy : 0.685 | Test accuracy : 0.664\n",
      "Epoch 162 | Train loss : 0.773 | Train accuracy : 0.686 | Test accuracy : 0.666\n",
      "Epoch 163 | Train loss : 0.777 | Train accuracy : 0.684 | Test accuracy : 0.666\n",
      "Epoch 164 | Train loss : 0.776 | Train accuracy : 0.684 | Test accuracy : 0.664\n",
      "Epoch 165 | Train loss : 0.776 | Train accuracy : 0.684 | Test accuracy : 0.666\n",
      "Epoch 166 | Train loss : 0.774 | Train accuracy : 0.686 | Test accuracy : 0.666\n",
      "Epoch 167 | Train loss : 0.776 | Train accuracy : 0.683 | Test accuracy : 0.661\n",
      "Epoch 168 | Train loss : 0.779 | Train accuracy : 0.684 | Test accuracy : 0.667\n",
      "Epoch 169 | Train loss : 0.773 | Train accuracy : 0.686 | Test accuracy : 0.667\n",
      "Epoch 170 | Train loss : 0.775 | Train accuracy : 0.685 | Test accuracy : 0.665\n",
      "Epoch 171 | Train loss : 0.773 | Train accuracy : 0.686 | Test accuracy : 0.666\n",
      "Epoch 172 | Train loss : 0.774 | Train accuracy : 0.687 | Test accuracy : 0.668\n",
      "Epoch 173 | Train loss : 0.773 | Train accuracy : 0.685 | Test accuracy : 0.663\n",
      "Epoch 174 | Train loss : 0.776 | Train accuracy : 0.686 | Test accuracy : 0.667\n",
      "Epoch 175 | Train loss : 0.776 | Train accuracy : 0.686 | Test accuracy : 0.664\n",
      "Epoch 176 | Train loss : 0.774 | Train accuracy : 0.686 | Test accuracy : 0.663\n",
      "Epoch 177 | Train loss : 0.772 | Train accuracy : 0.687 | Test accuracy : 0.667\n",
      "Epoch 178 | Train loss : 0.774 | Train accuracy : 0.685 | Test accuracy : 0.664\n",
      "Epoch 179 | Train loss : 0.772 | Train accuracy : 0.686 | Test accuracy : 0.665\n",
      "Epoch 180 | Train loss : 0.774 | Train accuracy : 0.685 | Test accuracy : 0.664\n",
      "Epoch 181 | Train loss : 0.775 | Train accuracy : 0.685 | Test accuracy : 0.665\n",
      "Epoch 182 | Train loss : 0.774 | Train accuracy : 0.686 | Test accuracy : 0.666\n",
      "Epoch 183 | Train loss : 0.775 | Train accuracy : 0.686 | Test accuracy : 0.662\n",
      "Epoch 184 | Train loss : 0.771 | Train accuracy : 0.686 | Test accuracy : 0.664\n",
      "Epoch 185 | Train loss : 0.773 | Train accuracy : 0.687 | Test accuracy : 0.667\n",
      "Epoch 186 | Train loss : 0.772 | Train accuracy : 0.687 | Test accuracy : 0.667\n",
      "Epoch 187 | Train loss : 0.772 | Train accuracy : 0.685 | Test accuracy : 0.665\n",
      "Epoch 188 | Train loss : 0.772 | Train accuracy : 0.685 | Test accuracy : 0.666\n",
      "Epoch 189 | Train loss : 0.772 | Train accuracy : 0.685 | Test accuracy : 0.665\n",
      "Epoch 190 | Train loss : 0.773 | Train accuracy : 0.686 | Test accuracy : 0.664\n",
      "Epoch 191 | Train loss : 0.773 | Train accuracy : 0.686 | Test accuracy : 0.665\n",
      "Epoch 192 | Train loss : 0.771 | Train accuracy : 0.687 | Test accuracy : 0.667\n",
      "Epoch 193 | Train loss : 0.770 | Train accuracy : 0.686 | Test accuracy : 0.664\n",
      "Epoch 194 | Train loss : 0.774 | Train accuracy : 0.687 | Test accuracy : 0.665\n",
      "Epoch 195 | Train loss : 0.771 | Train accuracy : 0.686 | Test accuracy : 0.665\n"
     ]
    }
   ],
   "source": [
    "epochs = 200\n",
    "batch_size = 64\n",
    "\n",
    "model = Classifier()\n",
    "\n",
    "# Loss\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "\n",
    "# Optimizer\n",
    "optimizer = optim.Adam(model.parameters(), 1e-3)\n",
    "\n",
    "# Training the model\n",
    "model.train(True)\n",
    "\n",
    "for e in range(epochs):\n",
    "    \n",
    "    for input, target in zip(train_input_.split(batch_size), train_target_.split(batch_size)):\n",
    "                             \n",
    "        output = model(input)\n",
    "        loss = criterion(output, target)\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        \n",
    "    model.train(False)\n",
    "    tr_output = model(train_input_)\n",
    "    te_output = model(test_input_)\n",
    "    tr_loss = criterion(tr_output, train_target_)\n",
    "    tr_acc = accuracy(tr_output, train_target_)\n",
    "    te_acc = accuracy(te_output, test_target_)\n",
    "    model.train(True)\n",
    "    print(\"Epoch {}\".format(e) +\\\n",
    "          \" | Train loss : {:.3f}\".format(tr_loss) +\\\n",
    "          \" | Train accuracy : {:.3f}\".format(tr_acc) +\\\n",
    "          \" | Test accuracy : {:.3f}\".format(te_acc))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}

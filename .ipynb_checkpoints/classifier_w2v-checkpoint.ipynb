{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "import torch\n",
    "from torch import nn\n",
    "from torch.nn import functional as F\n",
    "from torch import optim\n",
    "import time\n",
    "\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "import ast"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "folder = '/dlabdata1/lugeon/'\n",
    "name = 'websites_40000_5cat_emb.gz'\n",
    "data = pd.read_csv(folder + name, \n",
    "                   header=0,\n",
    "                   index_col = 0,\n",
    "                   names=['emb', 'len', 'cat0'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>emb</th>\n",
       "      <th>len</th>\n",
       "      <th>cat0</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>[-0.01415306854087751, 0.054038308285563406, -...</td>\n",
       "      <td>48215</td>\n",
       "      <td>Arts</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>[0.04585096571180555, -0.018588595920138888, 0...</td>\n",
       "      <td>23</td>\n",
       "      <td>Arts</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>[-0.009650490500710228, -0.02681940252130682, ...</td>\n",
       "      <td>24</td>\n",
       "      <td>Arts</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>Arts</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>[0.04253146113181601, 0.036278354878328284, 0....</td>\n",
       "      <td>683</td>\n",
       "      <td>Arts</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                 emb    len  cat0\n",
       "0  [-0.01415306854087751, 0.054038308285563406, -...  48215  Arts\n",
       "1  [0.04585096571180555, -0.018588595920138888, 0...     23  Arts\n",
       "2  [-0.009650490500710228, -0.02681940252130682, ...     24  Arts\n",
       "3                                                NaN      0  Arts\n",
       "4  [0.04253146113181601, 0.036278354878328284, 0....    683  Arts"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = data[data.emb.notnull()]\n",
    "data = data[data.len >= 100]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "data['emb'] = data.apply(lambda row: np.array(ast.literal_eval(row.emb)), axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(105995, 3)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Science      22686\n",
       "Computers    22206\n",
       "Arts         21176\n",
       "Kids         20849\n",
       "Sports       19078\n",
       "Name: cat0, dtype: int64"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.cat0.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def categorize(s):\n",
    "    if s == 'Kids':\n",
    "        return 0\n",
    "    if s == 'Science':\n",
    "        return 1\n",
    "    if s == 'Arts':\n",
    "        return 2\n",
    "    if s == 'Computers':\n",
    "        return 3\n",
    "    if s == 'Sports':\n",
    "        return 4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "data['cat_no'] = data.apply(lambda row: categorize(row.cat0), axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "embeddings = np.concatenate(data.emb.values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "embedding_dim = 300\n",
    "train_input = torch.tensor(embeddings)\n",
    "train_input = torch.reshape(train_input, (-1, embedding_dim)).float()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([105995, 300])"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_input.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "cat_no = data.cat_no.values\n",
    "train_target = torch.tensor(cat_no).long()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([105995])"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_target.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "id = np.arange(train_input.shape[0])\n",
    "np.random.shuffle(id)\n",
    "\n",
    "training_set_size = 90_000\n",
    "\n",
    "tr_id = id[:training_set_size]\n",
    "te_id = id[training_set_size:]\n",
    "\n",
    "train_input_ = train_input[tr_id]\n",
    "test_input_ = train_input[te_id]\n",
    "\n",
    "train_target_ = train_target[tr_id]\n",
    "test_target_ = train_target[te_id]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Science      19159\n",
       "Computers    18912\n",
       "Arts         17990\n",
       "Kids         17691\n",
       "Sports       16248\n",
       "Name: cat0, dtype: int64"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.iloc[tr_id].cat0.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Science      3527\n",
       "Computers    3294\n",
       "Arts         3186\n",
       "Kids         3158\n",
       "Sports       2830\n",
       "Name: cat0, dtype: int64"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.iloc[te_id].cat0.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Classifier(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(Classifier, self).__init__()\n",
    "        self.fc1 = nn.Linear(300, 300)\n",
    "        self.fc2 = nn.Linear(300, 300)\n",
    "        self.fc3 = nn.Linear(300, 100)\n",
    "        self.fc4 = nn.Linear(100, 5)\n",
    "        self.drop = nn.Dropout(0.1)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.fc1(x)\n",
    "        #x = self.drop(x)\n",
    "        x = self.fc2(F.relu(x))\n",
    "        # x = self.drop(x)\n",
    "        x = self.fc3(F.relu(x))\n",
    "        #x = self.drop(x)\n",
    "        x = self.fc4(F.relu(x))\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "def accuracy(output, target):\n",
    "    nb_samples = output.shape[0]\n",
    "    \n",
    "    # Convert probability to decision\n",
    "    output_class = torch.argmax(output, 1)\n",
    "    \n",
    "    nb_correct = (output_class == target).sum().item()\n",
    "    return nb_correct / nb_samples\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0 | Train loss : 0.848 | Train accuracy : 0.689 | Test accuracy : 0.681\n",
      "Epoch 1 | Train loss : 0.790 | Train accuracy : 0.710 | Test accuracy : 0.703\n",
      "Epoch 2 | Train loss : 0.760 | Train accuracy : 0.719 | Test accuracy : 0.712\n",
      "Epoch 3 | Train loss : 0.740 | Train accuracy : 0.728 | Test accuracy : 0.718\n",
      "Epoch 4 | Train loss : 0.725 | Train accuracy : 0.733 | Test accuracy : 0.723\n",
      "Epoch 5 | Train loss : 0.711 | Train accuracy : 0.737 | Test accuracy : 0.727\n",
      "Epoch 6 | Train loss : 0.697 | Train accuracy : 0.743 | Test accuracy : 0.730\n",
      "Epoch 7 | Train loss : 0.691 | Train accuracy : 0.745 | Test accuracy : 0.731\n",
      "Epoch 8 | Train loss : 0.684 | Train accuracy : 0.747 | Test accuracy : 0.732\n",
      "Epoch 9 | Train loss : 0.677 | Train accuracy : 0.751 | Test accuracy : 0.734\n",
      "Epoch 10 | Train loss : 0.662 | Train accuracy : 0.757 | Test accuracy : 0.739\n",
      "Epoch 11 | Train loss : 0.664 | Train accuracy : 0.756 | Test accuracy : 0.736\n",
      "Epoch 12 | Train loss : 0.655 | Train accuracy : 0.759 | Test accuracy : 0.739\n",
      "Epoch 13 | Train loss : 0.657 | Train accuracy : 0.758 | Test accuracy : 0.736\n",
      "Epoch 14 | Train loss : 0.648 | Train accuracy : 0.762 | Test accuracy : 0.739\n",
      "Epoch 15 | Train loss : 0.642 | Train accuracy : 0.764 | Test accuracy : 0.740\n",
      "Epoch 16 | Train loss : 0.639 | Train accuracy : 0.766 | Test accuracy : 0.740\n",
      "Epoch 17 | Train loss : 0.640 | Train accuracy : 0.766 | Test accuracy : 0.741\n",
      "Epoch 18 | Train loss : 0.631 | Train accuracy : 0.768 | Test accuracy : 0.739\n",
      "Epoch 19 | Train loss : 0.628 | Train accuracy : 0.769 | Test accuracy : 0.743\n",
      "Epoch 20 | Train loss : 0.624 | Train accuracy : 0.771 | Test accuracy : 0.743\n",
      "Epoch 21 | Train loss : 0.615 | Train accuracy : 0.772 | Test accuracy : 0.742\n",
      "Epoch 22 | Train loss : 0.612 | Train accuracy : 0.775 | Test accuracy : 0.743\n",
      "Epoch 23 | Train loss : 0.603 | Train accuracy : 0.776 | Test accuracy : 0.742\n",
      "Epoch 24 | Train loss : 0.601 | Train accuracy : 0.777 | Test accuracy : 0.743\n",
      "Epoch 25 | Train loss : 0.602 | Train accuracy : 0.777 | Test accuracy : 0.740\n",
      "Epoch 26 | Train loss : 0.609 | Train accuracy : 0.776 | Test accuracy : 0.741\n",
      "Epoch 27 | Train loss : 0.593 | Train accuracy : 0.780 | Test accuracy : 0.743\n",
      "Epoch 28 | Train loss : 0.597 | Train accuracy : 0.780 | Test accuracy : 0.742\n",
      "Epoch 29 | Train loss : 0.589 | Train accuracy : 0.781 | Test accuracy : 0.742\n",
      "Epoch 30 | Train loss : 0.591 | Train accuracy : 0.782 | Test accuracy : 0.741\n",
      "Epoch 31 | Train loss : 0.588 | Train accuracy : 0.783 | Test accuracy : 0.742\n",
      "Epoch 32 | Train loss : 0.585 | Train accuracy : 0.785 | Test accuracy : 0.744\n",
      "Epoch 33 | Train loss : 0.576 | Train accuracy : 0.787 | Test accuracy : 0.744\n",
      "Epoch 34 | Train loss : 0.569 | Train accuracy : 0.790 | Test accuracy : 0.744\n",
      "Epoch 35 | Train loss : 0.565 | Train accuracy : 0.791 | Test accuracy : 0.746\n",
      "Epoch 36 | Train loss : 0.563 | Train accuracy : 0.791 | Test accuracy : 0.746\n",
      "Epoch 37 | Train loss : 0.564 | Train accuracy : 0.793 | Test accuracy : 0.747\n",
      "Epoch 38 | Train loss : 0.563 | Train accuracy : 0.793 | Test accuracy : 0.745\n",
      "Epoch 39 | Train loss : 0.563 | Train accuracy : 0.791 | Test accuracy : 0.745\n",
      "Epoch 40 | Train loss : 0.549 | Train accuracy : 0.796 | Test accuracy : 0.745\n",
      "Epoch 41 | Train loss : 0.557 | Train accuracy : 0.795 | Test accuracy : 0.746\n",
      "Epoch 42 | Train loss : 0.563 | Train accuracy : 0.795 | Test accuracy : 0.743\n",
      "Epoch 43 | Train loss : 0.557 | Train accuracy : 0.797 | Test accuracy : 0.744\n",
      "Epoch 44 | Train loss : 0.556 | Train accuracy : 0.797 | Test accuracy : 0.744\n",
      "Epoch 45 | Train loss : 0.552 | Train accuracy : 0.797 | Test accuracy : 0.743\n",
      "Epoch 46 | Train loss : 0.547 | Train accuracy : 0.799 | Test accuracy : 0.745\n",
      "Epoch 47 | Train loss : 0.547 | Train accuracy : 0.800 | Test accuracy : 0.744\n",
      "Epoch 48 | Train loss : 0.545 | Train accuracy : 0.801 | Test accuracy : 0.745\n",
      "Epoch 49 | Train loss : 0.535 | Train accuracy : 0.804 | Test accuracy : 0.745\n",
      "Epoch 50 | Train loss : 0.539 | Train accuracy : 0.800 | Test accuracy : 0.740\n",
      "Epoch 51 | Train loss : 0.541 | Train accuracy : 0.801 | Test accuracy : 0.739\n",
      "Epoch 52 | Train loss : 0.537 | Train accuracy : 0.804 | Test accuracy : 0.740\n",
      "Epoch 53 | Train loss : 0.538 | Train accuracy : 0.802 | Test accuracy : 0.736\n",
      "Epoch 54 | Train loss : 0.540 | Train accuracy : 0.802 | Test accuracy : 0.739\n",
      "Epoch 55 | Train loss : 0.546 | Train accuracy : 0.802 | Test accuracy : 0.737\n",
      "Epoch 56 | Train loss : 0.549 | Train accuracy : 0.802 | Test accuracy : 0.736\n",
      "Epoch 57 | Train loss : 0.541 | Train accuracy : 0.803 | Test accuracy : 0.735\n",
      "Epoch 58 | Train loss : 0.549 | Train accuracy : 0.801 | Test accuracy : 0.733\n",
      "Epoch 59 | Train loss : 0.544 | Train accuracy : 0.803 | Test accuracy : 0.737\n",
      "Epoch 60 | Train loss : 0.544 | Train accuracy : 0.806 | Test accuracy : 0.739\n",
      "Epoch 61 | Train loss : 0.548 | Train accuracy : 0.804 | Test accuracy : 0.736\n",
      "Epoch 62 | Train loss : 0.562 | Train accuracy : 0.802 | Test accuracy : 0.736\n",
      "Epoch 63 | Train loss : 0.559 | Train accuracy : 0.802 | Test accuracy : 0.733\n",
      "Epoch 64 | Train loss : 0.551 | Train accuracy : 0.805 | Test accuracy : 0.735\n",
      "Epoch 65 | Train loss : 0.555 | Train accuracy : 0.804 | Test accuracy : 0.735\n",
      "Epoch 66 | Train loss : 0.552 | Train accuracy : 0.806 | Test accuracy : 0.735\n",
      "Epoch 67 | Train loss : 0.571 | Train accuracy : 0.803 | Test accuracy : 0.733\n",
      "Epoch 68 | Train loss : 0.560 | Train accuracy : 0.805 | Test accuracy : 0.734\n",
      "Epoch 69 | Train loss : 0.558 | Train accuracy : 0.806 | Test accuracy : 0.737\n",
      "Epoch 70 | Train loss : 0.558 | Train accuracy : 0.808 | Test accuracy : 0.736\n",
      "Epoch 71 | Train loss : 0.561 | Train accuracy : 0.807 | Test accuracy : 0.733\n",
      "Epoch 72 | Train loss : 0.568 | Train accuracy : 0.805 | Test accuracy : 0.733\n",
      "Epoch 73 | Train loss : 0.566 | Train accuracy : 0.807 | Test accuracy : 0.732\n",
      "Epoch 74 | Train loss : 0.567 | Train accuracy : 0.807 | Test accuracy : 0.733\n",
      "Epoch 75 | Train loss : 0.578 | Train accuracy : 0.806 | Test accuracy : 0.732\n",
      "Epoch 76 | Train loss : 0.576 | Train accuracy : 0.805 | Test accuracy : 0.729\n",
      "Epoch 77 | Train loss : 0.572 | Train accuracy : 0.807 | Test accuracy : 0.731\n",
      "Epoch 78 | Train loss : 0.585 | Train accuracy : 0.803 | Test accuracy : 0.728\n",
      "Epoch 79 | Train loss : 0.576 | Train accuracy : 0.806 | Test accuracy : 0.729\n",
      "Epoch 80 | Train loss : 0.590 | Train accuracy : 0.804 | Test accuracy : 0.729\n",
      "Epoch 81 | Train loss : 0.581 | Train accuracy : 0.805 | Test accuracy : 0.728\n",
      "Epoch 82 | Train loss : 0.599 | Train accuracy : 0.803 | Test accuracy : 0.728\n",
      "Epoch 83 | Train loss : 0.590 | Train accuracy : 0.805 | Test accuracy : 0.728\n",
      "Epoch 84 | Train loss : 0.596 | Train accuracy : 0.804 | Test accuracy : 0.725\n",
      "Epoch 85 | Train loss : 0.591 | Train accuracy : 0.806 | Test accuracy : 0.728\n",
      "Epoch 86 | Train loss : 0.606 | Train accuracy : 0.802 | Test accuracy : 0.724\n",
      "Epoch 87 | Train loss : 0.598 | Train accuracy : 0.803 | Test accuracy : 0.722\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-29-7a6641666cd4>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     20\u001b[0m         \u001b[0mloss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcriterion\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarget\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     21\u001b[0m         \u001b[0moptimizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mzero_grad\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 22\u001b[0;31m         \u001b[0mloss\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     23\u001b[0m         \u001b[0moptimizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     24\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/dlabdata1/lugeon/lugeon-env/lib/python3.8/site-packages/torch/tensor.py\u001b[0m in \u001b[0;36mbackward\u001b[0;34m(self, gradient, retain_graph, create_graph)\u001b[0m\n\u001b[1;32m    183\u001b[0m                 \u001b[0mproducts\u001b[0m\u001b[0;34m.\u001b[0m \u001b[0mDefaults\u001b[0m \u001b[0mto\u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m`\u001b[0m\u001b[0;31m`\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;31m`\u001b[0m\u001b[0;31m`\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    184\u001b[0m         \"\"\"\n\u001b[0;32m--> 185\u001b[0;31m         \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mautograd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgradient\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mretain_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcreate_graph\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    186\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    187\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mregister_hook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhook\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/dlabdata1/lugeon/lugeon-env/lib/python3.8/site-packages/torch/autograd/__init__.py\u001b[0m in \u001b[0;36mbackward\u001b[0;34m(tensors, grad_tensors, retain_graph, create_graph, grad_variables)\u001b[0m\n\u001b[1;32m    123\u001b[0m         \u001b[0mretain_graph\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcreate_graph\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    124\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 125\u001b[0;31m     Variable._execution_engine.run_backward(\n\u001b[0m\u001b[1;32m    126\u001b[0m         \u001b[0mtensors\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgrad_tensors\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mretain_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcreate_graph\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    127\u001b[0m         allow_unreachable=True)  # allow_unreachable flag\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "epochs = 400\n",
    "batch_size = 64\n",
    "\n",
    "model = Classifier()\n",
    "\n",
    "# Loss\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "\n",
    "# Optimizer\n",
    "optimizer = optim.Adam(model.parameters(), 1e-4)\n",
    "\n",
    "# Training the model\n",
    "model.train(True)\n",
    "\n",
    "for e in range(epochs):\n",
    "    \n",
    "    for input, target in zip(train_input_.split(batch_size), train_target_.split(batch_size)):\n",
    "                             \n",
    "        output = model(input)\n",
    "        loss = criterion(output, target)\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        \n",
    "    model.train(False)\n",
    "    tr_output = model(train_input_)\n",
    "    te_output = model(test_input_)\n",
    "    tr_loss = criterion(tr_output, train_target_)\n",
    "    tr_acc = accuracy(tr_output, train_target_)\n",
    "    te_acc = accuracy(te_output, test_target_)\n",
    "    model.train(True)\n",
    "    print(\"Epoch {}\".format(e) +\\\n",
    "          \" | Train loss : {:.3f}\".format(tr_loss) +\\\n",
    "          \" | Train accuracy : {:.3f}\".format(tr_acc) +\\\n",
    "          \" | Test accuracy : {:.3f}\".format(te_acc))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
